{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, RandomResizedCrop, RandomVerticalFlip, RandomHorizontalFlip\n",
    "from torchvision.transforms import ColorJitter, ToTensor, Normalize\n",
    "\n",
    "FRUIT360_PATH = Path(\".\") / \"fruits-360_dataset\" / \"fruits-360\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "train_transform = Compose([\n",
    "    RandomHorizontalFlip(),    \n",
    "    RandomResizedCrop(size=32),\n",
    "    ColorJitter(brightness=0.12),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "val_transform = Compose([\n",
    "    RandomResizedCrop(size=32),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 8\n",
    "\n",
    "train_dataset = ImageFolder((FRUIT360_PATH /\"Training\").as_posix(), transform=train_transform, target_transform=None)\n",
    "val_dataset = ImageFolder((FRUIT360_PATH /\"Test\").as_posix(), transform=val_transform, target_transform=None)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                          num_workers=num_workers,\n",
    "                          drop_last=True, pin_memory=\"cuda\" in device)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True,\n",
    "                        num_workers=num_workers,\n",
    "                        drop_last=False, pin_memory=\"cuda\" in device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mynet\n",
    "from torchvision.models.squeezenet import squeezenet1_1\n",
    "\n",
    "#model = squeezenet1_1(pretrained=False, num_classes=93)\n",
    "model = mynet.ConvNet(num_classes=93)\n",
    "#model.classifier[-1] = nn.AdaptiveAvgPool2d(1)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, _prepare_batch\n",
    "\n",
    "def process_function(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y = _prepare_batch(batch, device=device)\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "trainer = Engine(process_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events\n",
    "\n",
    "log_interval = 50\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    iteration = (engine.state.iteration - 1) % len(train_loader) + 1\n",
    "    if iteration % log_interval == 0:\n",
    "        print(\"Epoch[{}] Iteration[{}/{}] Loss: {:.4f}\"\n",
    "              .format(engine.state.epoch, \n",
    "                         iteration, \n",
    "                         len(train_loader), \n",
    "                         engine.state.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.metrics import Loss, CategoricalAccuracy, Precision, Recall\n",
    "\n",
    "metrics = {\n",
    "    'avg_loss': Loss(criterion),\n",
    "    'avg_accuracy': CategoricalAccuracy(),\n",
    "    'avg_precision': Precision(average=True),\n",
    "    'avg_recall': Recall(average=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import create_supervised_evaluator\n",
    "\n",
    "train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(train_dataset))\n",
    "random_indices = np.random.permutation(indices)[:len(val_dataset)]\n",
    "train_subset = Subset(train_dataset, indices=random_indices)\n",
    "\n",
    "train_eval_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True,\n",
    "                                num_workers=num_workers, \n",
    "                                drop_last=True, pin_memory=\"cuda\" in device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def compute_and_display_offline_train_metrics(engine):\n",
    "    epoch = engine.state.epoch\n",
    "    print(\"Compute train metrics...\")\n",
    "    metrics = train_evaluator.run(train_eval_loader).metrics\n",
    "    print(\"Training Results - Epoch: {}  Average Loss: {:.4f} | Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f}\"\n",
    "          .format(engine.state.epoch, \n",
    "                      metrics['avg_loss'], \n",
    "                      metrics['avg_accuracy'], \n",
    "                      metrics['avg_precision'], \n",
    "                      metrics['avg_recall']))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def compute_and_display_val_metrics(engine):\n",
    "    epoch = engine.state.epoch\n",
    "    print(\"Compute validation metrics...\")\n",
    "    metrics = val_evaluator.run(val_loader).metrics\n",
    "    print(\"Validation Results - Epoch: {}  Average Loss: {:.4f} | Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f}\"\n",
    "          .format(engine.state.epoch, \n",
    "                      metrics['avg_loss'], \n",
    "                      metrics['avg_accuracy'], \n",
    "                      metrics['avg_precision'], \n",
    "                      metrics['avg_recall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "lr_scheduler = ExponentialLR(optimizer, gamma=1)\n",
    "\n",
    "@trainer.on(Events.EPOCH_STARTED)\n",
    "def update_lr_scheduler(engine):\n",
    "    lr_scheduler.step()\n",
    "    # Вывод значений скорости обучения:\n",
    "    if len(optimizer.param_groups) == 1:\n",
    "        lr = float(optimizer.param_groups[0]['lr'])\n",
    "        print(\"Learning rate: {}\".format(lr))\n",
    "    else:\n",
    "        for i, param_group in enumerate(optimizer.param_groups):\n",
    "            lr = float(param_group['lr'])\n",
    "            print(\"Learning rate (group {}): {}\".format(i, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.handlers import ModelCheckpoint\n",
    "\n",
    "def score_function(engine):\n",
    "    val_avg_accuracy = engine.state.metrics['avg_accuracy']\n",
    "    return val_avg_accuracy\n",
    "\n",
    "best_model_saver = ModelCheckpoint(\"best_models\",  \n",
    "                                   filename_prefix=\"model\",\n",
    "                                   score_name=\"val_accuracy\",  \n",
    "                                   score_function=score_function,\n",
    "                                   n_saved=3,\n",
    "                                   save_as_state_dict=True,\n",
    "                                   create_dir=True)\n",
    "\n",
    "\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, \n",
    "                                best_model_saver, \n",
    "                                {\"best_model\": model})\n",
    "\n",
    "training_saver = ModelCheckpoint(\"checkpoint\",\n",
    "                             filename_prefix=\"checkpoint\",\n",
    "                             save_interval=1000,\n",
    "                             n_saved=1,\n",
    "                             save_as_state_dict=True,\n",
    "                             create_dir=True)\n",
    "\n",
    "to_save = {\"model\": model, \"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler} \n",
    "trainer.add_event_handler(Events.ITERATION_COMPLETED, training_saver, to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.handlers import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, \n",
    "                              score_function=score_function, \n",
    "                              trainer=trainer)\n",
    "\n",
    "val_evaluator.add_event_handler(Events.EPOCH_COMPLETED, early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.01\n",
      "Epoch[1] Iteration[50/371] Loss: 4.3245\n",
      "Epoch[1] Iteration[100/371] Loss: 3.6551\n",
      "Epoch[1] Iteration[150/371] Loss: 3.0498\n",
      "Epoch[1] Iteration[200/371] Loss: 2.7232\n",
      "Epoch[1] Iteration[250/371] Loss: 2.5947\n",
      "Epoch[1] Iteration[300/371] Loss: 1.9119\n",
      "Epoch[1] Iteration[350/371] Loss: 1.7364\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 1  Average Loss: 1.8238 | Accuracy: 0.4764 | Precision: 0.5693 | Recall: 0.4680\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 1  Average Loss: 1.8302 | Accuracy: 0.4675 | Precision: 0.5509 | Recall: 0.4593\n",
      "Learning rate: 0.01\n",
      "Epoch[2] Iteration[50/371] Loss: 1.7889\n",
      "Epoch[2] Iteration[100/371] Loss: 1.6482\n",
      "Epoch[2] Iteration[150/371] Loss: 1.3564\n",
      "Epoch[2] Iteration[200/371] Loss: 1.5517\n",
      "Epoch[2] Iteration[250/371] Loss: 1.3361\n",
      "Epoch[2] Iteration[300/371] Loss: 1.4403\n",
      "Epoch[2] Iteration[350/371] Loss: 1.0390\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 2  Average Loss: 1.2786 | Accuracy: 0.6343 | Precision: 0.6799 | Recall: 0.6282\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 2  Average Loss: 1.2716 | Accuracy: 0.6400 | Precision: 0.6911 | Recall: 0.6290\n",
      "Learning rate: 0.01\n",
      "Epoch[3] Iteration[50/371] Loss: 1.1165\n",
      "Epoch[3] Iteration[100/371] Loss: 1.0988\n",
      "Epoch[3] Iteration[150/371] Loss: 0.8754\n",
      "Epoch[3] Iteration[200/371] Loss: 1.1412\n",
      "Epoch[3] Iteration[250/371] Loss: 0.9242\n",
      "Epoch[3] Iteration[300/371] Loss: 1.0667\n",
      "Epoch[3] Iteration[350/371] Loss: 1.0378\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 3  Average Loss: 0.8490 | Accuracy: 0.7492 | Precision: 0.7912 | Recall: 0.7465\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 3  Average Loss: 0.8226 | Accuracy: 0.7640 | Precision: 0.7963 | Recall: 0.7587\n",
      "Learning rate: 0.01\n",
      "Epoch[4] Iteration[50/371] Loss: 0.8772\n",
      "Epoch[4] Iteration[100/371] Loss: 0.8065\n",
      "Epoch[4] Iteration[150/371] Loss: 1.0205\n",
      "Epoch[4] Iteration[200/371] Loss: 0.7273\n",
      "Epoch[4] Iteration[250/371] Loss: 0.5209\n",
      "Epoch[4] Iteration[300/371] Loss: 0.8218\n",
      "Epoch[4] Iteration[350/371] Loss: 0.7534\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 4  Average Loss: 0.7226 | Accuracy: 0.7899 | Precision: 0.8141 | Recall: 0.7889\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 4  Average Loss: 0.7249 | Accuracy: 0.7967 | Precision: 0.8237 | Recall: 0.7928\n",
      "Learning rate: 0.01\n",
      "Epoch[5] Iteration[50/371] Loss: 0.5649\n",
      "Epoch[5] Iteration[100/371] Loss: 0.8219\n",
      "Epoch[5] Iteration[150/371] Loss: 0.6470\n",
      "Epoch[5] Iteration[200/371] Loss: 0.6477\n",
      "Epoch[5] Iteration[250/371] Loss: 0.6890\n",
      "Epoch[5] Iteration[300/371] Loss: 0.6760\n",
      "Epoch[5] Iteration[350/371] Loss: 0.6135\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 5  Average Loss: 0.5735 | Accuracy: 0.8288 | Precision: 0.8495 | Recall: 0.8244\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 5  Average Loss: 0.5720 | Accuracy: 0.8254 | Precision: 0.8438 | Recall: 0.8204\n",
      "Learning rate: 0.01\n",
      "Epoch[6] Iteration[50/371] Loss: 0.6409\n",
      "Epoch[6] Iteration[100/371] Loss: 0.4589\n",
      "Epoch[6] Iteration[150/371] Loss: 0.5341\n",
      "Epoch[6] Iteration[200/371] Loss: 0.6113\n",
      "Epoch[6] Iteration[250/371] Loss: 0.7086\n",
      "Epoch[6] Iteration[300/371] Loss: 0.5014\n",
      "Epoch[6] Iteration[350/371] Loss: 0.5479\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 6  Average Loss: 0.4798 | Accuracy: 0.8608 | Precision: 0.8666 | Recall: 0.8593\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 6  Average Loss: 0.4746 | Accuracy: 0.8619 | Precision: 0.8690 | Recall: 0.8599\n",
      "Learning rate: 0.01\n",
      "Epoch[7] Iteration[50/371] Loss: 0.6200\n",
      "Epoch[7] Iteration[100/371] Loss: 0.4137\n",
      "Epoch[7] Iteration[150/371] Loss: 0.3699\n",
      "Epoch[7] Iteration[200/371] Loss: 0.4705\n",
      "Epoch[7] Iteration[250/371] Loss: 0.5956\n",
      "Epoch[7] Iteration[300/371] Loss: 0.6164\n",
      "Epoch[7] Iteration[350/371] Loss: 0.4476\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 7  Average Loss: 0.4678 | Accuracy: 0.8602 | Precision: 0.8676 | Recall: 0.8607\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 7  Average Loss: 0.4673 | Accuracy: 0.8630 | Precision: 0.8710 | Recall: 0.8614\n",
      "Learning rate: 0.01\n",
      "Epoch[8] Iteration[50/371] Loss: 0.6080\n",
      "Epoch[8] Iteration[100/371] Loss: 0.4640\n",
      "Epoch[8] Iteration[150/371] Loss: 0.3292\n",
      "Epoch[8] Iteration[200/371] Loss: 0.4196\n",
      "Epoch[8] Iteration[250/371] Loss: 0.3158\n",
      "Epoch[8] Iteration[300/371] Loss: 0.5727\n",
      "Epoch[8] Iteration[350/371] Loss: 0.5795\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 8  Average Loss: 0.4289 | Accuracy: 0.8703 | Precision: 0.8821 | Recall: 0.8701\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 8  Average Loss: 0.4227 | Accuracy: 0.8722 | Precision: 0.8852 | Recall: 0.8703\n",
      "Learning rate: 0.01\n",
      "Epoch[9] Iteration[50/371] Loss: 0.3594\n",
      "Epoch[9] Iteration[100/371] Loss: 0.4518\n",
      "Epoch[9] Iteration[150/371] Loss: 0.4025\n",
      "Epoch[9] Iteration[200/371] Loss: 0.4395\n",
      "Epoch[9] Iteration[250/371] Loss: 0.5105\n",
      "Epoch[9] Iteration[300/371] Loss: 0.3713\n",
      "Epoch[9] Iteration[350/371] Loss: 0.3268\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 9  Average Loss: 0.3682 | Accuracy: 0.8875 | Precision: 0.8981 | Recall: 0.8871\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 9  Average Loss: 0.3692 | Accuracy: 0.8834 | Precision: 0.8956 | Recall: 0.8799\n",
      "Learning rate: 0.01\n",
      "Epoch[10] Iteration[50/371] Loss: 0.3814\n",
      "Epoch[10] Iteration[100/371] Loss: 0.4261\n",
      "Epoch[10] Iteration[150/371] Loss: 0.4076\n",
      "Epoch[10] Iteration[200/371] Loss: 0.4871\n",
      "Epoch[10] Iteration[250/371] Loss: 0.4252\n",
      "Epoch[10] Iteration[300/371] Loss: 0.2862\n",
      "Epoch[10] Iteration[350/371] Loss: 0.3970\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 10  Average Loss: 0.3535 | Accuracy: 0.8925 | Precision: 0.8997 | Recall: 0.8929\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 10  Average Loss: 0.3647 | Accuracy: 0.8862 | Precision: 0.8966 | Recall: 0.8842\n",
      "Learning rate: 0.01\n",
      "Epoch[11] Iteration[50/371] Loss: 0.2724\n",
      "Epoch[11] Iteration[100/371] Loss: 0.2996\n",
      "Epoch[11] Iteration[150/371] Loss: 0.2492\n",
      "Epoch[11] Iteration[200/371] Loss: 0.3448\n",
      "Epoch[11] Iteration[250/371] Loss: 0.4259\n",
      "Epoch[11] Iteration[300/371] Loss: 0.3339\n",
      "Epoch[11] Iteration[350/371] Loss: 0.4521\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 11  Average Loss: 0.3262 | Accuracy: 0.8994 | Precision: 0.8973 | Recall: 0.8978\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 11  Average Loss: 0.3415 | Accuracy: 0.8962 | Precision: 0.9034 | Recall: 0.8935\n",
      "Learning rate: 0.01\n",
      "Epoch[12] Iteration[50/371] Loss: 0.2623\n",
      "Epoch[12] Iteration[100/371] Loss: 0.2231\n",
      "Epoch[12] Iteration[150/371] Loss: 0.2774\n",
      "Epoch[12] Iteration[200/371] Loss: 0.4687\n",
      "Epoch[12] Iteration[250/371] Loss: 0.3932\n",
      "Epoch[12] Iteration[300/371] Loss: 0.3532\n",
      "Epoch[12] Iteration[350/371] Loss: 0.2325\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 12  Average Loss: 0.2935 | Accuracy: 0.9125 | Precision: 0.9161 | Recall: 0.9118\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 12  Average Loss: 0.3104 | Accuracy: 0.9097 | Precision: 0.9131 | Recall: 0.9074\n",
      "Learning rate: 0.01\n",
      "Epoch[13] Iteration[50/371] Loss: 0.2575\n",
      "Epoch[13] Iteration[100/371] Loss: 0.2870\n",
      "Epoch[13] Iteration[150/371] Loss: 0.2694\n",
      "Epoch[13] Iteration[200/371] Loss: 0.3143\n",
      "Epoch[13] Iteration[250/371] Loss: 0.2937\n",
      "Epoch[13] Iteration[300/371] Loss: 0.1731\n",
      "Epoch[13] Iteration[350/371] Loss: 0.3269\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 13  Average Loss: 0.2701 | Accuracy: 0.9184 | Precision: 0.9241 | Recall: 0.9166\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 13  Average Loss: 0.2979 | Accuracy: 0.9060 | Precision: 0.9137 | Recall: 0.9020\n",
      "Learning rate: 0.01\n",
      "Epoch[14] Iteration[50/371] Loss: 0.2812\n",
      "Epoch[14] Iteration[100/371] Loss: 0.3294\n",
      "Epoch[14] Iteration[150/371] Loss: 0.4246\n",
      "Epoch[14] Iteration[200/371] Loss: 0.2908\n",
      "Epoch[14] Iteration[250/371] Loss: 0.2264\n",
      "Epoch[14] Iteration[300/371] Loss: 0.2045\n",
      "Epoch[14] Iteration[350/371] Loss: 0.2236\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 14  Average Loss: 0.2332 | Accuracy: 0.9302 | Precision: 0.9347 | Recall: 0.9304\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 14  Average Loss: 0.2625 | Accuracy: 0.9193 | Precision: 0.9236 | Recall: 0.9177\n",
      "Learning rate: 0.01\n",
      "Epoch[15] Iteration[50/371] Loss: 0.2097\n",
      "Epoch[15] Iteration[100/371] Loss: 0.2314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[15] Iteration[150/371] Loss: 0.2121\n",
      "Epoch[15] Iteration[200/371] Loss: 0.3122\n",
      "Epoch[15] Iteration[250/371] Loss: 0.2413\n",
      "Epoch[15] Iteration[300/371] Loss: 0.3980\n",
      "Epoch[15] Iteration[350/371] Loss: 0.1487\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 15  Average Loss: 0.2196 | Accuracy: 0.9328 | Precision: 0.9353 | Recall: 0.9313\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 15  Average Loss: 0.2464 | Accuracy: 0.9237 | Precision: 0.9270 | Recall: 0.9215\n",
      "Learning rate: 0.01\n",
      "Epoch[16] Iteration[50/371] Loss: 0.2198\n",
      "Epoch[16] Iteration[100/371] Loss: 0.3493\n",
      "Epoch[16] Iteration[150/371] Loss: 0.2241\n",
      "Epoch[16] Iteration[200/371] Loss: 0.2095\n",
      "Epoch[16] Iteration[250/371] Loss: 0.1343\n",
      "Epoch[16] Iteration[300/371] Loss: 0.2219\n",
      "Epoch[16] Iteration[350/371] Loss: 0.3085\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 16  Average Loss: 0.2254 | Accuracy: 0.9290 | Precision: 0.9325 | Recall: 0.9280\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 16  Average Loss: 0.2410 | Accuracy: 0.9248 | Precision: 0.9293 | Recall: 0.9219\n",
      "Learning rate: 0.01\n",
      "Epoch[17] Iteration[50/371] Loss: 0.3813\n",
      "Epoch[17] Iteration[100/371] Loss: 0.1807\n",
      "Epoch[17] Iteration[150/371] Loss: 0.1905\n",
      "Epoch[17] Iteration[200/371] Loss: 0.1843\n",
      "Epoch[17] Iteration[250/371] Loss: 0.2723\n",
      "Epoch[17] Iteration[300/371] Loss: 0.2225\n",
      "Epoch[17] Iteration[350/371] Loss: 0.3255\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 17  Average Loss: 0.2353 | Accuracy: 0.9241 | Precision: 0.9292 | Recall: 0.9240\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 17  Average Loss: 0.2464 | Accuracy: 0.9209 | Precision: 0.9260 | Recall: 0.9201\n",
      "Learning rate: 0.01\n",
      "Epoch[18] Iteration[50/371] Loss: 0.2976\n",
      "Epoch[18] Iteration[100/371] Loss: 0.2415\n",
      "Epoch[18] Iteration[150/371] Loss: 0.2710\n",
      "Epoch[18] Iteration[200/371] Loss: 0.0954\n",
      "Epoch[18] Iteration[250/371] Loss: 0.2923\n",
      "Epoch[18] Iteration[300/371] Loss: 0.3315\n",
      "Epoch[18] Iteration[350/371] Loss: 0.2114\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 18  Average Loss: 0.2245 | Accuracy: 0.9308 | Precision: 0.9327 | Recall: 0.9308\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 18  Average Loss: 0.2438 | Accuracy: 0.9285 | Precision: 0.9328 | Recall: 0.9265\n",
      "Learning rate: 0.01\n",
      "Epoch[19] Iteration[50/371] Loss: 0.4393\n",
      "Epoch[19] Iteration[100/371] Loss: 0.3247\n",
      "Epoch[19] Iteration[150/371] Loss: 0.2964\n",
      "Epoch[19] Iteration[200/371] Loss: 0.2421\n",
      "Epoch[19] Iteration[250/371] Loss: 0.2381\n",
      "Epoch[19] Iteration[300/371] Loss: 0.1717\n",
      "Epoch[19] Iteration[350/371] Loss: 0.2386\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 19  Average Loss: 0.1971 | Accuracy: 0.9395 | Precision: 0.9413 | Recall: 0.9389\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 19  Average Loss: 0.2127 | Accuracy: 0.9341 | Precision: 0.9362 | Recall: 0.9321\n",
      "Learning rate: 0.01\n",
      "Epoch[20] Iteration[50/371] Loss: 0.2332\n",
      "Epoch[20] Iteration[100/371] Loss: 0.3528\n",
      "Epoch[20] Iteration[150/371] Loss: 0.3216\n",
      "Epoch[20] Iteration[200/371] Loss: 0.3248\n",
      "Epoch[20] Iteration[250/371] Loss: 0.2279\n",
      "Epoch[20] Iteration[300/371] Loss: 0.1756\n",
      "Epoch[20] Iteration[350/371] Loss: 0.1830\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 20  Average Loss: 0.2184 | Accuracy: 0.9343 | Precision: 0.9386 | Recall: 0.9333\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 20  Average Loss: 0.2390 | Accuracy: 0.9282 | Precision: 0.9335 | Recall: 0.9265\n",
      "Learning rate: 0.01\n",
      "Epoch[21] Iteration[50/371] Loss: 0.2105\n",
      "Epoch[21] Iteration[100/371] Loss: 0.1646\n",
      "Epoch[21] Iteration[150/371] Loss: 0.1284\n",
      "Epoch[21] Iteration[200/371] Loss: 0.2708\n",
      "Epoch[21] Iteration[250/371] Loss: 0.1709\n",
      "Epoch[21] Iteration[300/371] Loss: 0.1911\n",
      "Epoch[21] Iteration[350/371] Loss: 0.1456\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 21  Average Loss: 0.2149 | Accuracy: 0.9321 | Precision: 0.9374 | Recall: 0.9324\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 21  Average Loss: 0.2282 | Accuracy: 0.9285 | Precision: 0.9347 | Recall: 0.9276\n",
      "Learning rate: 0.01\n",
      "Epoch[22] Iteration[50/371] Loss: 0.2499\n",
      "Epoch[22] Iteration[100/371] Loss: 0.0951\n",
      "Epoch[22] Iteration[150/371] Loss: 0.1269\n",
      "Epoch[22] Iteration[200/371] Loss: 0.3602\n",
      "Epoch[22] Iteration[250/371] Loss: 0.1091\n",
      "Epoch[22] Iteration[300/371] Loss: 0.2165\n",
      "Epoch[22] Iteration[350/371] Loss: 0.2659\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 22  Average Loss: 0.2047 | Accuracy: 0.9354 | Precision: 0.9411 | Recall: 0.9348\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 22  Average Loss: 0.2275 | Accuracy: 0.9281 | Precision: 0.9351 | Recall: 0.9261\n",
      "Learning rate: 0.01\n",
      "Epoch[23] Iteration[50/371] Loss: 0.2592\n",
      "Epoch[23] Iteration[100/371] Loss: 0.2069\n",
      "Epoch[23] Iteration[150/371] Loss: 0.2718\n",
      "Epoch[23] Iteration[200/371] Loss: 0.1131\n",
      "Epoch[23] Iteration[250/371] Loss: 0.1228\n",
      "Epoch[23] Iteration[300/371] Loss: 0.3225\n",
      "Epoch[23] Iteration[350/371] Loss: 0.2196\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 23  Average Loss: 0.2100 | Accuracy: 0.9351 | Precision: 0.9384 | Recall: 0.9356\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 23  Average Loss: 0.2219 | Accuracy: 0.9295 | Precision: 0.9335 | Recall: 0.9276\n",
      "Learning rate: 0.01\n",
      "Epoch[24] Iteration[50/371] Loss: 0.0920\n",
      "Epoch[24] Iteration[100/371] Loss: 0.2572\n",
      "Epoch[24] Iteration[150/371] Loss: 0.1435\n",
      "Epoch[24] Iteration[200/371] Loss: 0.2409\n",
      "Epoch[24] Iteration[250/371] Loss: 0.2760\n",
      "Epoch[24] Iteration[300/371] Loss: 0.2140\n",
      "Epoch[24] Iteration[350/371] Loss: 0.2688\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 24  Average Loss: 0.1800 | Accuracy: 0.9440 | Precision: 0.9458 | Recall: 0.9444\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 24  Average Loss: 0.1948 | Accuracy: 0.9423 | Precision: 0.9433 | Recall: 0.9408\n",
      "Learning rate: 0.01\n",
      "Epoch[25] Iteration[50/371] Loss: 0.1661\n",
      "Epoch[25] Iteration[100/371] Loss: 0.1485\n",
      "Epoch[25] Iteration[150/371] Loss: 0.2672\n",
      "Epoch[25] Iteration[200/371] Loss: 0.2032\n",
      "Epoch[25] Iteration[250/371] Loss: 0.1531\n",
      "Epoch[25] Iteration[300/371] Loss: 0.2621\n",
      "Epoch[25] Iteration[350/371] Loss: 0.1076\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 25  Average Loss: 0.1700 | Accuracy: 0.9473 | Precision: 0.9482 | Recall: 0.9465\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 25  Average Loss: 0.1755 | Accuracy: 0.9459 | Precision: 0.9478 | Recall: 0.9438\n",
      "Learning rate: 0.01\n",
      "Epoch[26] Iteration[50/371] Loss: 0.2022\n",
      "Epoch[26] Iteration[100/371] Loss: 0.1891\n",
      "Epoch[26] Iteration[150/371] Loss: 0.2715\n",
      "Epoch[26] Iteration[200/371] Loss: 0.1627\n",
      "Epoch[26] Iteration[250/371] Loss: 0.2208\n",
      "Epoch[26] Iteration[300/371] Loss: 0.2521\n",
      "Epoch[26] Iteration[350/371] Loss: 0.1756\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 26  Average Loss: 0.1600 | Accuracy: 0.9490 | Precision: 0.9508 | Recall: 0.9501\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 26  Average Loss: 0.1861 | Accuracy: 0.9427 | Precision: 0.9447 | Recall: 0.9418\n",
      "Learning rate: 0.01\n",
      "Epoch[27] Iteration[50/371] Loss: 0.2472\n",
      "Epoch[27] Iteration[100/371] Loss: 0.2738\n",
      "Epoch[27] Iteration[150/371] Loss: 0.2498\n",
      "Epoch[27] Iteration[200/371] Loss: 0.1790\n",
      "Epoch[27] Iteration[250/371] Loss: 0.2064\n",
      "Epoch[27] Iteration[300/371] Loss: 0.1553\n",
      "Epoch[27] Iteration[350/371] Loss: 0.2673\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 27  Average Loss: 0.1609 | Accuracy: 0.9497 | Precision: 0.9512 | Recall: 0.9493\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 27  Average Loss: 0.1872 | Accuracy: 0.9410 | Precision: 0.9424 | Recall: 0.9388\n",
      "Learning rate: 0.01\n",
      "Epoch[28] Iteration[50/371] Loss: 0.1531\n",
      "Epoch[28] Iteration[100/371] Loss: 0.1961\n",
      "Epoch[28] Iteration[150/371] Loss: 0.1980\n",
      "Epoch[28] Iteration[200/371] Loss: 0.1938\n",
      "Epoch[28] Iteration[250/371] Loss: 0.2347\n",
      "Epoch[28] Iteration[300/371] Loss: 0.2258\n",
      "Epoch[28] Iteration[350/371] Loss: 0.1714\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 28  Average Loss: 0.1558 | Accuracy: 0.9500 | Precision: 0.9506 | Recall: 0.9505\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 28  Average Loss: 0.1687 | Accuracy: 0.9481 | Precision: 0.9494 | Recall: 0.9469\n",
      "Learning rate: 0.01\n",
      "Epoch[29] Iteration[50/371] Loss: 0.2340\n",
      "Epoch[29] Iteration[100/371] Loss: 0.2024\n",
      "Epoch[29] Iteration[150/371] Loss: 0.2081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[29] Iteration[200/371] Loss: 0.1488\n",
      "Epoch[29] Iteration[250/371] Loss: 0.1602\n",
      "Epoch[29] Iteration[300/371] Loss: 0.2135\n",
      "Epoch[29] Iteration[350/371] Loss: 0.2044\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 29  Average Loss: 0.1468 | Accuracy: 0.9534 | Precision: 0.9552 | Recall: 0.9531\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 29  Average Loss: 0.1549 | Accuracy: 0.9510 | Precision: 0.9521 | Recall: 0.9496\n",
      "Learning rate: 0.01\n",
      "Epoch[30] Iteration[50/371] Loss: 0.2169\n",
      "Epoch[30] Iteration[100/371] Loss: 0.1903\n",
      "Epoch[30] Iteration[150/371] Loss: 0.1675\n",
      "Epoch[30] Iteration[200/371] Loss: 0.2515\n",
      "Epoch[30] Iteration[250/371] Loss: 0.1496\n",
      "Epoch[30] Iteration[300/371] Loss: 0.1450\n",
      "Epoch[30] Iteration[350/371] Loss: 0.2284\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 30  Average Loss: 0.1404 | Accuracy: 0.9543 | Precision: 0.9559 | Recall: 0.9550\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 30  Average Loss: 0.1688 | Accuracy: 0.9476 | Precision: 0.9491 | Recall: 0.9462\n",
      "Learning rate: 0.01\n",
      "Epoch[31] Iteration[50/371] Loss: 0.1908\n",
      "Epoch[31] Iteration[100/371] Loss: 0.1492\n",
      "Epoch[31] Iteration[150/371] Loss: 0.2441\n",
      "Epoch[31] Iteration[200/371] Loss: 0.1286\n",
      "Epoch[31] Iteration[250/371] Loss: 0.1926\n",
      "Epoch[31] Iteration[300/371] Loss: 0.1250\n",
      "Epoch[31] Iteration[350/371] Loss: 0.1607\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 31  Average Loss: 0.1496 | Accuracy: 0.9527 | Precision: 0.9551 | Recall: 0.9524\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 31  Average Loss: 0.1668 | Accuracy: 0.9465 | Precision: 0.9488 | Recall: 0.9445\n",
      "Learning rate: 0.01\n",
      "Epoch[32] Iteration[50/371] Loss: 0.1516\n",
      "Epoch[32] Iteration[100/371] Loss: 0.1391\n",
      "Epoch[32] Iteration[150/371] Loss: 0.1602\n",
      "Epoch[32] Iteration[200/371] Loss: 0.2201\n",
      "Epoch[32] Iteration[250/371] Loss: 0.1529\n",
      "Epoch[32] Iteration[300/371] Loss: 0.1217\n",
      "Epoch[32] Iteration[350/371] Loss: 0.1672\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 32  Average Loss: 0.1309 | Accuracy: 0.9570 | Precision: 0.9585 | Recall: 0.9574\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 32  Average Loss: 0.1484 | Accuracy: 0.9560 | Precision: 0.9570 | Recall: 0.9555\n",
      "Learning rate: 0.01\n",
      "Epoch[33] Iteration[50/371] Loss: 0.2553\n",
      "Epoch[33] Iteration[100/371] Loss: 0.1499\n",
      "Epoch[33] Iteration[150/371] Loss: 0.2216\n",
      "Epoch[33] Iteration[200/371] Loss: 0.2191\n",
      "Epoch[33] Iteration[250/371] Loss: 0.2336\n",
      "Epoch[33] Iteration[300/371] Loss: 0.1623\n",
      "Epoch[33] Iteration[350/371] Loss: 0.2497\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 33  Average Loss: 0.1383 | Accuracy: 0.9550 | Precision: 0.9564 | Recall: 0.9553\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 33  Average Loss: 0.1537 | Accuracy: 0.9534 | Precision: 0.9548 | Recall: 0.9525\n",
      "Learning rate: 0.01\n",
      "Epoch[34] Iteration[50/371] Loss: 0.2178\n",
      "Epoch[34] Iteration[100/371] Loss: 0.1299\n",
      "Epoch[34] Iteration[150/371] Loss: 0.1467\n",
      "Epoch[34] Iteration[200/371] Loss: 0.1705\n",
      "Epoch[34] Iteration[250/371] Loss: 0.1410\n",
      "Epoch[34] Iteration[300/371] Loss: 0.1876\n",
      "Epoch[34] Iteration[350/371] Loss: 0.1710\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 34  Average Loss: 0.1260 | Accuracy: 0.9584 | Precision: 0.9590 | Recall: 0.9578\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 34  Average Loss: 0.1552 | Accuracy: 0.9536 | Precision: 0.9556 | Recall: 0.9524\n",
      "Learning rate: 0.01\n",
      "Epoch[35] Iteration[50/371] Loss: 0.1386\n",
      "Epoch[35] Iteration[100/371] Loss: 0.1416\n",
      "Epoch[35] Iteration[150/371] Loss: 0.1458\n",
      "Epoch[35] Iteration[200/371] Loss: 0.1229\n",
      "Epoch[35] Iteration[250/371] Loss: 0.1632\n",
      "Epoch[35] Iteration[300/371] Loss: 0.1884\n",
      "Epoch[35] Iteration[350/371] Loss: 0.2627\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 35  Average Loss: 0.1175 | Accuracy: 0.9616 | Precision: 0.9634 | Recall: 0.9618\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 35  Average Loss: 0.1459 | Accuracy: 0.9543 | Precision: 0.9568 | Recall: 0.9534\n",
      "Learning rate: 0.01\n",
      "Epoch[36] Iteration[50/371] Loss: 0.1744\n",
      "Epoch[36] Iteration[100/371] Loss: 0.1675\n",
      "Epoch[36] Iteration[150/371] Loss: 0.0804\n",
      "Epoch[36] Iteration[200/371] Loss: 0.1407\n",
      "Epoch[36] Iteration[250/371] Loss: 0.0822\n",
      "Epoch[36] Iteration[300/371] Loss: 0.0783\n",
      "Epoch[36] Iteration[350/371] Loss: 0.1394\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 36  Average Loss: 0.1239 | Accuracy: 0.9584 | Precision: 0.9603 | Recall: 0.9592\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 36  Average Loss: 0.1511 | Accuracy: 0.9535 | Precision: 0.9562 | Recall: 0.9523\n",
      "Learning rate: 0.01\n",
      "Epoch[37] Iteration[50/371] Loss: 0.1389\n",
      "Epoch[37] Iteration[100/371] Loss: 0.1116\n",
      "Epoch[37] Iteration[150/371] Loss: 0.2274\n",
      "Epoch[37] Iteration[200/371] Loss: 0.0678\n",
      "Epoch[37] Iteration[250/371] Loss: 0.1028\n",
      "Epoch[37] Iteration[300/371] Loss: 0.1122\n",
      "Epoch[37] Iteration[350/371] Loss: 0.1317\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 37  Average Loss: 0.1291 | Accuracy: 0.9594 | Precision: 0.9595 | Recall: 0.9597\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 37  Average Loss: 0.1639 | Accuracy: 0.9519 | Precision: 0.9529 | Recall: 0.9510\n",
      "Learning rate: 0.01\n",
      "Epoch[38] Iteration[50/371] Loss: 0.1898\n",
      "Epoch[38] Iteration[100/371] Loss: 0.1627\n",
      "Epoch[38] Iteration[150/371] Loss: 0.1736\n",
      "Epoch[38] Iteration[200/371] Loss: 0.1564\n",
      "Epoch[38] Iteration[250/371] Loss: 0.2046\n",
      "Epoch[38] Iteration[300/371] Loss: 0.1040\n",
      "Epoch[38] Iteration[350/371] Loss: 0.1455\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 38  Average Loss: 0.1202 | Accuracy: 0.9618 | Precision: 0.9636 | Recall: 0.9603\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 38  Average Loss: 0.1490 | Accuracy: 0.9542 | Precision: 0.9567 | Recall: 0.9532\n",
      "Learning rate: 0.01\n",
      "Epoch[39] Iteration[50/371] Loss: 0.1745\n",
      "Epoch[39] Iteration[100/371] Loss: 0.2634\n",
      "Epoch[39] Iteration[150/371] Loss: 0.0781\n",
      "Epoch[39] Iteration[200/371] Loss: 0.2181\n",
      "Epoch[39] Iteration[250/371] Loss: 0.1404\n",
      "Epoch[39] Iteration[300/371] Loss: 0.1634\n",
      "Epoch[39] Iteration[350/371] Loss: 0.1419\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 39  Average Loss: 0.1193 | Accuracy: 0.9616 | Precision: 0.9624 | Recall: 0.9607\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 39  Average Loss: 0.1495 | Accuracy: 0.9551 | Precision: 0.9561 | Recall: 0.9535\n",
      "Learning rate: 0.01\n",
      "Epoch[40] Iteration[50/371] Loss: 0.1120\n",
      "Epoch[40] Iteration[100/371] Loss: 0.1559\n",
      "Epoch[40] Iteration[150/371] Loss: 0.1207\n",
      "Epoch[40] Iteration[200/371] Loss: 0.1130\n",
      "Epoch[40] Iteration[250/371] Loss: 0.2520\n",
      "Epoch[40] Iteration[300/371] Loss: 0.0981\n",
      "Epoch[40] Iteration[350/371] Loss: 0.1395\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 40  Average Loss: 0.1254 | Accuracy: 0.9594 | Precision: 0.9606 | Recall: 0.9603\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 40  Average Loss: 0.1528 | Accuracy: 0.9522 | Precision: 0.9536 | Recall: 0.9516\n",
      "Learning rate: 0.01\n",
      "Epoch[41] Iteration[50/371] Loss: 0.1771\n",
      "Epoch[41] Iteration[100/371] Loss: 0.0752\n",
      "Epoch[41] Iteration[150/371] Loss: 0.1455\n",
      "Epoch[41] Iteration[200/371] Loss: 0.0913\n",
      "Epoch[41] Iteration[250/371] Loss: 0.1350\n",
      "Epoch[41] Iteration[300/371] Loss: 0.1419\n",
      "Epoch[41] Iteration[350/371] Loss: 0.1145\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 41  Average Loss: 0.1391 | Accuracy: 0.9553 | Precision: 0.9577 | Recall: 0.9563\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 41  Average Loss: 0.1581 | Accuracy: 0.9536 | Precision: 0.9558 | Recall: 0.9525\n",
      "Learning rate: 0.01\n",
      "Epoch[42] Iteration[50/371] Loss: 0.1148\n",
      "Epoch[42] Iteration[100/371] Loss: 0.1416\n",
      "Epoch[42] Iteration[150/371] Loss: 0.0981\n",
      "Epoch[42] Iteration[200/371] Loss: 0.1400\n",
      "Epoch[42] Iteration[250/371] Loss: 0.1132\n",
      "Epoch[42] Iteration[300/371] Loss: 0.0586\n",
      "Epoch[42] Iteration[350/371] Loss: 0.0800\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 42  Average Loss: 0.1232 | Accuracy: 0.9614 | Precision: 0.9624 | Recall: 0.9609\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 42  Average Loss: 0.1420 | Accuracy: 0.9547 | Precision: 0.9571 | Recall: 0.9531\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 100\n",
    "output = trainer.run(train_loader, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "\n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.ds[index][0], index\n",
    "\n",
    "test_dataset = TestDataset(val_dataset)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=num_workers, \n",
    "                         drop_last=False, pin_memory=\"cuda\" in device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from ignite._utils import convert_tensor\n",
    "\n",
    "def _prepare_batch(batch):\n",
    "    x, index = batch\n",
    "    x = convert_tensor(x, device=device)\n",
    "    return x, index\n",
    "\n",
    "def inference_update(engine, batch):\n",
    "    x, indices = _prepare_batch(batch)\n",
    "    y_pred = model(x)\n",
    "    y_pred = F.softmax(y_pred, dim=1)\n",
    "    return {\"y_pred\": convert_tensor(y_pred, device='cpu'), \"indices\": indices}\n",
    "\n",
    "model.eval()\n",
    "inferencer = Engine(inference_update) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@inferencer.on(Events.EPOCH_COMPLETED)\n",
    "def log_tta(engine):\n",
    "    print(\"TTA {} / {}\".format(engine.state.epoch, n_tta))\n",
    "\n",
    "n_tta = 3\n",
    "num_classes = 93\n",
    "n_samples = len(val_dataset)\n",
    "\n",
    "# Массив для хранения предсказаний\n",
    "y_probas_tta = np.zeros((n_samples, num_classes, n_tta), dtype=np.float32)\n",
    "\n",
    "@inferencer.on(Events.ITERATION_COMPLETED)\n",
    "def save_results(engine):\n",
    "    output = engine.state.output\n",
    "    tta_index = engine.state.epoch - 1\n",
    "    start_index = ((engine.state.iteration - 1) % len(test_loader)) * batch_size\n",
    "    end_index = min(start_index + batch_size, n_samples)\n",
    "    batch_y_probas = output['y_pred'].detach().numpy()\n",
    "    y_probas_tta[start_index:end_index, :, tta_index] = batch_y_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mynet.ConvNet(num_classes=93)\n",
    "#model.classifier[-1] = nn.AdaptiveAvgPool2d(1)\n",
    "model = model.to(device)\n",
    "\n",
    "model_state_dict = torch.load(\"best_models/model_best_model_32_val_accuracy=0.9559937.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencer.run(test_loader, max_epochs=n_tta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.mean(y_probas_tta, axis=-1)\n",
    "y_preds = np.argmax(y_probas, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_true = [y for _, y in val_dataset]\n",
    "accuracy_score(y_test_true, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
